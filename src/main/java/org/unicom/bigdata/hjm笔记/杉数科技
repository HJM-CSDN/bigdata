1.HDFS当中数据可以保存多少份？ 任意份
2.Hadoop集群瓶颈：磁盘IO。磁盘IO是不可以扩充的
3.spark各个节点通过什么方式进行通信：Akka还是Netty？
  到了1.6.0版本，Netty居然完成取代了Akka，承担Spark内部所有的RPC通信以及数据流传输。
4.Spark累加器有哪些特点？
    全局唯一、对于Executor只能修改但不可读，只对Driver可读、不同的Executor修改不会互相覆盖
    提供自定义类型累加器

简答：
1.MR的shuffle和Spark的Shuffle区别？


2.Hive和Hbase的区别？

    共同点：
    1.hbase与hive都是架构在hadoop之上的。都是用hadoop作为底层存储
    区别：
    2.Hive是建立在Hadoop之上为了减少MapReduce jobs编写工作的批处理系统，HBase是为了支持弥补Hadoop对实时操作的缺陷的项目 。
    3.想象你在操作RMDB数据库，如果是全表扫描，就用Hive+Hadoop,如果是索引访问，就用HBase+Hadoop 。
    4.Hive query就是MapReduce jobs可以从5分钟到数小时不止，HBase是非常高效的，肯定比Hive高效的多。
    5.Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce，Hive中的表纯逻辑。
    6.hive借用hadoop的MapReduce来完成一些hive中的命令的执行
    7.hbase是物理表，不是逻辑表，提供一个超大的内存hash表，搜索引擎通过它来存储索引，方便查询操作。
    8.hbase是列存储。
    9.hdfs作为底层存储，hdfs是存放文件的系统，而Hbase负责组织文件。
    10.hive需要用到hdfs存储文件，需要用到MapReduce计算框架。

3.如何对一个不确定规模的数据进行排序？





简答题：
一、给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，请找出每个文件的前5个
最多的URL，要求统计出来的这5个URL在另一个文件中也存在。
   方案1：可以估计每个文件安的大小为5G×64=320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。
         考虑采取分而治之的方法。
  遍历文件a，对每个url求取103x21，然后根据所取得的值将url分别存储到1000个小文件（记为83x21）中。这样每个小文件的大约为300M。

  遍历文件b，采取和a相同的方式将url分别存储到1000各小文件（记为81x21）。这样处理后，所有可能相同的url都在对应的小文件（179x21）
  中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。

  求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set
  中，如果是，那么就是共同的url，存到文件里面就可以了。

   方案2：如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿
   bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。
   ---------------------


见spark2x
编程题：
    1.现在有一天气数据如下：
      2000,12，04,10
      2000,11,01，-20
      2012,12,23,30
      2012,12,24,15
意为年、月、日、温度，请用二次排序输出如下期望的样子
    2012-12 30,15
    2012-12 10,-20
