示例：
    ./bin/spark-submit \
     --master spark://192.168.1.1:7077 \
     --num-executors 100 \ ##executor的数量
     --executor-memory 6G \
     --executor-cores 4 \ #分配给每个executor的内核数
     --total-executor-cores 400 \ ##standalone default all cores
     --driver-memory 1G \
     --conf spark.default.parallelism=1000 \
     --conf spark.storage.memoryFraction=0.5 \
     --conf spark.shuffle.memoryFraction=0.3 \

参数：
    -master:集群的master地址
    -deploy-mode:driver的运行模式，client或者cluster模式，默认为client
    -class：应用程序的主类（用于Java或者Scala应用）
    -name: 应用程序的名称
    -jars：作业执行过程中使用到的其他jar，可以使用逗号分隔添加多个
    -conf：其他额外的spark配置属性
    -driver-memory：driver节点的内存大小，如2G,默认为1024M
    -executor-memory：每个executor的执行内存。
   –total-executor-cores	给所有executor的所有内核数。（仅用于spark standalone或者mesos集群中）
   –executor-cores	分配给每个executor的内核数。（仅用于spark standalone或者yarn集群中）
   –driver-cores	driver的内核数。（仅yarn）
   –queue	作业执行的队列。（仅yarn）
   –num-executors	executor的数量。（仅yarn）


-spark.storage.memoryFraction
参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，
可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。
参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。
避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作
比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业
的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。
---------------------
-spark.shuffle.memoryFraction
参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，
默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，
那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。
参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比
比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着
task执行用户代码的内存不够用，那么同样建议调低这个参数的值。
---------------------










